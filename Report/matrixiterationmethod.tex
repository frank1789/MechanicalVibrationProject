\section{Matrix Iteration Method}\label{sec:mim}
the matrix iteration method assumes that the natural frequencies are distinct
and well separated such that \(\omega_1 < \omega_2 < \dots < \omega_n\).
The iteration starting by selecting a trial vector \(\vec{\mathbf{X}}_{1}\),
which is then premultiplied by the dynamical matrix \([D]\).
The resulting column vector is then normalized, usually by making one of its
components equal to unity.
The normalized column vector is premultiplied by \([D]\) to obtain a third
column vector, which is normalized in the same way as before and become still
another trial column vector.
The process is repeated until the successive column vectors converge to a common
vector: the fundamental eigenvector.
According to the expansion theorem, any arbitrary \(n\)-dimensional vector
\(\vec{\mathbf{X}}_{1}\) can be expressed as linear combination of the \(n\)
orthogonal eigenvectors of the system \(\vec{\mathbf{X}}^{(i)}\).
\begin{equation}\label{eq:expasniontheorem}
	\sum_{i = 1}^{n} = c_{i}\,\vec{\mathbf{X}}^{(n)}
\end{equation}
where \(c_{i}\) are unknown constant number to be determined.
As view before, it is possible premultiply \(\vec{\mathbf{X}}_{1}\) by matrix
\([D]\) obtaining:
\begin{equation}\label{eq:equationmultiply}
	[D] \vec{\mathbf{X}}_{1} = 	c_{1}\, [D] \,\vec{\mathbf{X}}_{(1)} +
								c_{2}\, [D] \,\vec{\mathbf{X}}_{(2)} + \dots +
  							c_{n}\, [D] \,\vec{\mathbf{X}}_{(n)}\\
\end{equation}
In according with the equation \(\lambda\,[I]\,\vec{X} = [D]\,\vec{X}\), then
we obtain
\(\vec{X}^{(n)} = \lambda\,[I]\,\vec{X}^{(n)} = \frac{1}{\omega^{2}_{n}}
\vec{X}^{(n)}\), thus after having substituted it in the equation
\eqref{eq:equationmultiply} one comes to the:
\begin{align}\label{eq:equationsubs}
  	[D]\,\vec{\mathbf{X}}_{1} &= \vec{\mathbf{X}}_{2}\\[0.75em]
      						&= \frac{c_{1}}{\omega^{2}_{1}}\,\vec{\mathbf{X}}^{(1)} +
		\frac{c_{2}}{\omega^{2}_{2}}\,\vec{\mathbf{X}}^{(2)} + \dots +
		\frac{c_{n}}{\omega^{2}_{n}}\,\vec{\mathbf{X}}^{(n)}
\end{align}
By repeating the process we obtain, after \(r_{th}\) iteration,
\begin{align}\label{eq:equationrth}
  	[D]\,\vec{\mathbf{X}}_{r} &= \vec{\mathbf{X}}_{r+1}\\[0.75em]
      						&= \frac{c_{1}}{\omega^{2r}_{1}}\,\vec{\mathbf{X}}^{(1)} +
		\frac{c_{2}}{\omega^{2r}_{2}}\,\vec{\mathbf{X}}^{(2)} + \dots +
		\frac{c_{n}}{\omega^{2r}_{n}}\,\vec{\mathbf{X}}^{(n)}
\end{align}
Since the natural frequencies are are assumed \(\omega_1 < \omega_2 < \dots <
\omega_n\), a sufficiently large value of \(r\) yields \(\frac{1}{\omega_1^{2r}}
>> \frac{1}{\omega_2^{2r}} >> \dots >> \frac{1}{\omega_n^{2r}}\). Thus the first
term in right-hand side of equation \eqref{eq:equationrth} becomes the only
significant one.
Which means that the \((r+1)_{th}\) trial vector becomes identical to the
fundamental modal vector to within a multiplicative constant
\(\vec{\mathbf{X}}_{r} = \frac{c_1}{\omega^{2(r-1)}_{1}}\vec{\mathbf{X}}^{(1)}\).
Then the fundamental natural frequency \(\omega_1\) can be found by taking the
ratio of any two corresponding components in the vectors \(\vec{\mathbf{X}}_{r}\)
and \(\vec{\mathbf{X}}_{r+1}\):
\begin{equation}
  \omega_1^{2} \simeq \frac{\vec{\mathbf{X}}_{n,r}}{\vec{\mathbf{X}}_{n,r+1}}
\end{equation}
where \(\vec{\mathbf{X}}_{n,r}\) and \(\vec{\mathbf{X}}_{n,r+1}\) are the
\(n_{th}\) elements of vector \(\vec{\mathbf{X}}_{r}\) and
\(\vec{\mathbf{X}}_{r+1}\), respectively.
\subsection{Intermediate natural frequencies}
Once the first natural frequency \(omega_1\) and the corresponding eigenvector
\(\vec{\mathbf{X}}^{(1)}\) are determined, it is possible proceed to find the
higher natural frequencies and the corresponding mode shapes.
To find the eigenvector \(\vec{\mathbf{X}}^{(i)}\), the previous eigenvector
\(\vec{\mathbf{X}}^{(i-1)}\) is normalized with respect to the mass matrix such
that \(\vec{\mathbf{X}}^{(i-1)^\top}\,[m]\,\vec{\mathbf{X}}^{(i-1)} = 1\).
The deflated matrix \([D_i]\) is the constructed as
\begin{equation}
  [D_i] =
  [D_i] - \lambda_{i-1}\vec{\mathbf{X}}^{(i-1)}\,\vec{\mathbf{X}}^{(i-1)^\top}[m]
\end{equation}
where \([D_1] = [D]\).
Once \([D_i]\) is constructed the iterative scheme
\begin{equation}
  \vec{\mathbf{X}}^{(r+1)} = [D_i]\,\vec{\mathbf{X}}^{(r)}
\end{equation}
is used.
\subsection{Result}\label{ssec:resultmim}
The whole procedure is performed for the case of free damping where the natural
frequencies are: \(\omega_{1} = 8.27843\) \si{\radian\per\second}, \(\omega_{2}
= 27.41224\) \si{\radian\per\second}, \(\omega_{3} = 41.85486\)
\si{\radian\per\second}.
The mode shapes results are shown in \eqref{eq:mimmodefree}.
\begin{equation}\label{eq:mimmodefree}
 \begin{bmatrix*}[r]
	1.00000 & 1.00000 & 1.00000 \\
	0.86540 & 0.21230 &-0.85499 \\
	0.61945 &-0.30643 &-0.30390 \\
	 \end{bmatrix*}
\end{equation}
%
In the case of proportional damping the natural frequencies are:
\(\omega_{1} = 8.27799\) \si{\radian\per\second}, \(\omega_{2} = 27.40863\)
\si{\radian\per\second}, \(\omega_{3} = 41.91576\) \si{\radian\per\second}.
The mode shapes results are shown in \eqref{eq:mimmodeprop}.
 \begin{equation}\label{eq:mimmodeprop}
 \begin{bmatrix*}[r]
	1.00000 & 1.00000 & 1.00000 \\
	0.86499 &-0.48006 &-2.46147 \\
	0.61907 &-1.28528 & 2.16954 \\
	 \end{bmatrix*}
\end{equation}
\subsection{Observation}\label{ssec:observationmim}
Although it is theoretically necessary to have \(r\rightarrow\infty\) for the 
convergence of the method, in practice only a finite number of iterations
suffices to obtain a reasonably good estimate of \(\omega_{1}\).
The actual number of iterations necessary to find the value of \(\omega_1\) to
within a desired degree of accuracy depends on how closely the arbitrary trial
vector \(\vec{\mathbf{X}}_{1}\) resembles the mode and how well \(\omega_1\)
and \(\omega_2\) are separated.
The required number of iterations is less if \(\omega_2\) is very large compared
to \(\omega_{1}\).
The method has a distinct advantage in that any computational errors made do not
yield incorrect results. Any error made in premultiplying
\(\vec{\mathbf{X}}_{i}\) by \([D]\) results in a vector other than the desired
one, \(\vec{\mathbf{X}}_{i+1}\).
But this wrong vector can be considered as a new trial vector.
This may delay the convergence but does not produce wrong results.
